# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“
è´Ÿè´£ç”Ÿæˆä¸“ä¸šçš„åˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–å†…å®¹
"""

import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from pathlib import Path

from .base_agent import BaseAgent, register_agent
from ..models.questionnaire import AnalysisReport, RiskAssessment, Questionnaire
from ..prompts.design_prompts import ReportGenerationPrompts

logger = logging.getLogger(__name__)

@register_agent
class ReportGeneratorAgent(BaseAgent):
    """æŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__(
            name="æŠ¥å‘Šç”Ÿæˆä¸“å®¶",
            description="ä¸“ä¸šç”Ÿæˆåˆ†ææŠ¥å‘Šçš„æ™ºèƒ½ä½“ï¼Œæ“…é•¿æŠ¥å‘Šå†™ä½œå’Œæ•°æ®å¯è§†åŒ–",
            expertise=["æŠ¥å‘Šå†™ä½œ", "åŒ»å­¦å†™ä½œ", "æ•°æ®å¯è§†åŒ–", "å†…å®¹ç»„ç»‡", "æ ¼å¼è§„èŒƒ"]
        )
        self.report_templates = self._load_report_templates()
        self.generated_reports: List[AnalysisReport] = []
    
    def _load_report_templates(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½æŠ¥å‘Šæ¨¡æ¿"""
        return {
            "comprehensive": {
                "name": "ç»¼åˆåˆ†ææŠ¥å‘Š",
                "sections": [
                    "æ‰§è¡Œæ‘˜è¦",
                    "èƒŒæ™¯ä»‹ç»",
                    "æ•°æ®æ¦‚è§ˆ",
                    "é£é™©è¯„ä¼°",
                    "æ•°æ®åˆ†æ",
                    "å…³é”®å‘ç°",
                    "å»ºè®®å’Œè¡ŒåŠ¨æ–¹æ¡ˆ",
                    "é™„å½•"
                ],
                "target_length": "3000-5000å­—"
            },
            "executive": {
                "name": "æ‰§è¡Œæ‘˜è¦æŠ¥å‘Š",
                "sections": [
                    "æ ¸å¿ƒå‘ç°",
                    "é£é™©è¯„ä¼°",
                    "å…³é”®å»ºè®®",
                    "åç»­è¡ŒåŠ¨"
                ],
                "target_length": "500-1000å­—"
            },
            "technical": {
                "name": "æŠ€æœ¯åˆ†ææŠ¥å‘Š",
                "sections": [
                    "æŠ€æœ¯æ‘˜è¦",
                    "æ–¹æ³•å­¦",
                    "æ•°æ®åˆ†æ",
                    "ç»Ÿè®¡ç»“æœ",
                    "æŠ€æœ¯è®¨è®º",
                    "ç»“è®º"
                ],
                "target_length": "2000-3000å­—"
            },
            "patient_friendly": {
                "name": "æ‚£è€…å‹å¥½æŠ¥å‘Š",
                "sections": [
                    "ç®€å•æ‘˜è¦",
                    "æ‚¨çš„å¥åº·çŠ¶å†µ",
                    "é£é™©è¯„ä¼°",
                    "å¥åº·å»ºè®®",
                    "ä¸‹ä¸€æ­¥è¡ŒåŠ¨",
                    "å¸¸è§é—®é¢˜"
                ],
                "target_length": "1500-2500å­—"
            }
        }
    
    async def process(self, input_data: Any) -> Any:
        """å¤„ç†æŠ¥å‘Šç”Ÿæˆè¯·æ±‚"""
        if isinstance(input_data, dict):
            # æ£€æŸ¥æ˜¯å¦åŒ…å« analysis_data é”®ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨æ–°çš„å¤„ç†æ–¹å¼
            if 'analysis_data' in input_data:
                return await self.generate_report(
                    analysis_data=input_data.get('analysis_data', {}),
                    risk_assessment=input_data.get('risk_assessment'),
                    questionnaire=input_data.get('questionnaire'),
                    report_type=input_data.get('report_type', 'comprehensive'),
                    user_profile=input_data.get('user_profile', {})
                )
            else:
                # å…¼å®¹æ—§çš„è°ƒç”¨æ–¹å¼
                return await self._process_legacy(input_data)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(input_data)}")
    
    async def _process_legacy(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        logger.info(f"ğŸ“ {self.name} å¼€å§‹ç”ŸæˆæŠ¥å‘Š")
        
        try:
            # æå–æ•°æ®
            questionnaire = analysis_data.get('questionnaire')
            answered_questions = analysis_data.get('answered_questions', [])
            conversation_history = analysis_data.get('conversation_history', [])
            
            # ä½¿ç”¨DeepSeekç”ŸæˆæŠ¥å‘Š
            report_content = await self._generate_report_with_llm(
                questionnaire, answered_questions, conversation_history
            )
            
            logger.info(f"âœ… {self.name} æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return {
                "status": "success",
                "report_content": report_content,
                "generated_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ {self.name} æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return {
                "status": "error",
                "report_content": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}",
                "error": str(e)
            }
    
    async def generate_report(self, analysis_data: Dict[str, Any],
                            risk_assessment: Optional[RiskAssessment] = None,
                            questionnaire: Optional[Questionnaire] = None,
                            report_type: str = "comprehensive",
                            user_profile: Optional[Dict[str, Any]] = None) -> AnalysisReport:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info(f"ğŸ“ {self.name} å¼€å§‹ç”Ÿæˆ{report_type}æŠ¥å‘Š")
        
        try:
            # è·å–æŠ¥å‘Šæ¨¡æ¿
            template = self.report_templates.get(report_type, self.report_templates["comprehensive"])
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            content = await self._generate_report_content(
                template, analysis_data, risk_assessment, questionnaire, user_profile
            )
            
            # åˆ›å»ºæŠ¥å‘Šå¯¹è±¡
            report = AnalysisReport(
                session_id=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                title=template["name"],
                content=content,
                risk_assessment=risk_assessment,
                data_insights=analysis_data.get('insights', []),
                generated_at=datetime.now()
            )
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            self.generated_reports.append(report)
            
            logger.info(f"âœ… {self.name} æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report.title}")
            return report
            
        except Exception as e:
            logger.error(f"âŒ {self.name} æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æŠ¥å‘Š
            return self._create_fallback_report(questionnaire, analysis_data.get('answered_questions', []))
    
    def _create_fallback_report(self, questionnaire, answered_questions) -> AnalysisReport:
        """åˆ›å»ºå¤‡ç”¨æŠ¥å‘Š"""
        from ..models.questionnaire import RiskLevel
        
        # åˆ›å»ºé»˜è®¤é£é™©è¯„ä¼°
        risk_assessment = RiskAssessment(
            session_id="fallback",
            overall_risk=RiskLevel.MEDIUM,
            risk_score=3.0,
            risk_factors=[{
                "factor": "default",
                "name": "é»˜è®¤è¯„ä¼°",
                "level": "moderate",
                "score": 3.0,
                "details": "æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è¯„ä¼°",
                "description": "å»ºè®®è¿›è¡Œä¸“ä¸šåŒ»å­¦è¯„ä¼°"
            }],
            recommendations=[
                "å»ºè®®è¿›è¡Œä¸“ä¸šåŒ»å­¦è¯„ä¼°",
                "å®šæœŸè¿›è¡Œå¥åº·æ£€æŸ¥",
                "ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼"
            ]
        )
        
        # ç”Ÿæˆç®€å•æŠ¥å‘Šå†…å®¹
        content = self._generate_fallback_report(questionnaire, answered_questions)
        
        return AnalysisReport(
            session_id=f"fallback_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            title="é»˜è®¤åˆ†ææŠ¥å‘Š",
            content=content,
            risk_assessment=risk_assessment,
            data_insights=[],
            generated_at=datetime.now()
        )
    
    async def _generate_report_with_llm(self, questionnaire, answered_questions, conversation_history) -> str:
        """ä½¿ç”¨DeepSeekç”ŸæˆæŠ¥å‘Š"""
        try:
            # æ„å»ºé—®ç­”æ•°æ®
            qa_data = []
            for response in answered_questions:
                question_text = "æœªçŸ¥é—®é¢˜"
                for q in questionnaire.questions:
                    if q.id == response.question_id:
                        question_text = q.text
                        break
                qa_data.append(f"é—®é¢˜ï¼š{question_text}\nå›ç­”ï¼š{response.answer}")
            
            qa_text = "\n\n".join(qa_data)
            
            # æ„å»ºæç¤ºè¯
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„åŒ»å­¦ä¸“å®¶ï¼Œéœ€è¦åŸºäºæ‚£è€…çš„é—®å·å›ç­”ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„è‚ºç™Œæ—©ç­›é£é™©è¯„ä¼°æŠ¥å‘Šã€‚

é—®å·ä¿¡æ¯ï¼š
- é—®å·æ ‡é¢˜ï¼š{questionnaire.title}
- æ€»é—®é¢˜æ•°ï¼š{len(questionnaire.questions)}
- å·²å›ç­”æ•°ï¼š{len(answered_questions)}

æ‚£è€…å›ç­”ï¼š
{qa_text}

è¯·ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„åŒ»å­¦æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹éƒ¨åˆ†ï¼š
1. åŸºæœ¬ä¿¡æ¯æ€»ç»“
2. é£é™©è¯„ä¼°ï¼ˆåŸºäºå›ç­”åˆ†æé£é™©å› ç´ ï¼‰
3. ä¸»è¦å‘ç°
4. åŒ»å­¦å»ºè®®
5. åç»­å»ºè®®

è¦æ±‚ï¼š
- è¯­è¨€ä¸“ä¸šä½†æ˜“æ‡‚
- åŸºäºåŒ»å­¦çŸ¥è¯†è¿›è¡Œåˆ†æ
- æä¾›å…·ä½“çš„å»ºè®®
- æ ¼å¼æ¸…æ™°ï¼Œç»“æ„å®Œæ•´

è¯·ç›´æ¥è¾“å‡ºæŠ¥å‘Šå†…å®¹ï¼Œä¸è¦æ·»åŠ å…¶ä»–è¯´æ˜ã€‚"""

            # è°ƒç”¨DeepSeek
            response = await self.call_llm(prompt)
            
            # æ¸…ç†å“åº”
            report = response.strip()
            if report and len(report) > 100:  # ç¡®ä¿æœ‰å®é™…å†…å®¹
                return report
            else:
                return self._generate_fallback_report(questionnaire, answered_questions)
                
        except Exception as e:
            logger.warning(f"âš ï¸ LLMæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            return self._generate_fallback_report(questionnaire, answered_questions)
    
    def _generate_fallback_report(self, questionnaire, answered_questions) -> str:
        """ç”Ÿæˆå¤‡ç”¨æŠ¥å‘Š"""
        report = "è‚ºç™Œæ—©ç­›é£é™©è¯„ä¼°æŠ¥å‘Š\n\n" + "=" * 50 + "\n\n"
        
        # åŸºæœ¬ä¿¡æ¯
        report += f"é—®å·å®Œæˆæ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n"
        report += f"é—®å·æ ‡é¢˜: {questionnaire.title}\n"
        report += f"æ€»é—®é¢˜æ•°: {len(questionnaire.questions)}\n"
        report += f"å·²å›ç­”æ•°: {len(answered_questions)}\n\n"
        
        # ç”¨æˆ·å›ç­”
        report += "ã€ç”¨æˆ·å›ç­”ã€‘\n"
        for i, response in enumerate(answered_questions, 1):
            question_text = "æœªçŸ¥é—®é¢˜"
            for q in questionnaire.questions:
                if q.id == response.question_id:
                    question_text = q.text
                    break
            
            report += f"{i}. {question_text}\n"
            report += f"   å›ç­”: {response.answer}\n\n"
        
        # ç®€å•å»ºè®®
        report += "ã€åŒ»å­¦å»ºè®®ã€‘\n"
        report += "1. å»ºè®®å®šæœŸè¿›è¡Œå¥åº·ä½“æ£€\n"
        report += "2. ä¿æŒè‰¯å¥½çš„ç”Ÿæ´»ä¹ æƒ¯\n"
        report += "3. å¦‚æœ‰å¼‚å¸¸ç—‡çŠ¶è¯·åŠæ—¶å°±åŒ»\n"
        report += "4. å®šæœŸè¿›è¡Œèƒ¸éƒ¨å½±åƒæ£€æŸ¥\n"
        
        return report

    async def _generate_report_content(self, template: Dict[str, Any],
                                     analysis_data: Dict[str, Any],
                                     risk_assessment: Optional[RiskAssessment],
                                     questionnaire: Optional[Questionnaire],
                                     user_profile: Optional[Dict[str, Any]]) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        content = f"# {template['name']}\n\n"
        content += f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n"
        content += f"**æŠ¥å‘Šç±»å‹**: {template['name']}\n"
        content += f"**ç›®æ ‡é•¿åº¦**: {template['target_length']}\n\n"
        
        # ç”Ÿæˆå„ä¸ªç« èŠ‚å†…å®¹
        for section in template['sections']:
            section_content = await self._generate_section_content(
                section, analysis_data, risk_assessment, questionnaire, user_profile
            )
            content += f"## {section}\n\n{section_content}\n\n"
        
        return content
    
    async def _generate_section_content(self, section: str,
                                      analysis_data: Dict[str, Any],
                                      risk_assessment: Optional[RiskAssessment],
                                      questionnaire: Optional[Questionnaire],
                                      user_profile: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆç« èŠ‚å†…å®¹"""
        if section == "æ‰§è¡Œæ‘˜è¦":
            return await self._generate_executive_summary_section(analysis_data, risk_assessment)
        elif section == "èƒŒæ™¯ä»‹ç»":
            return self._generate_background_section(questionnaire, user_profile)
        elif section == "æ•°æ®æ¦‚è§ˆ":
            return self._generate_data_overview_section(analysis_data)
        elif section == "é£é™©è¯„ä¼°":
            return self._generate_risk_assessment_section(risk_assessment)
        elif section == "æ•°æ®åˆ†æ":
            return self._generate_data_analysis_section(analysis_data)
        elif section == "å…³é”®å‘ç°":
            return self._generate_key_findings_section(analysis_data)
        elif section == "å»ºè®®å’Œè¡ŒåŠ¨æ–¹æ¡ˆ":
            return await self._generate_recommendations_section(analysis_data, risk_assessment, user_profile)
        elif section == "é™„å½•":
            return self._generate_appendix_section(analysis_data, questionnaire)
        elif section == "æ ¸å¿ƒå‘ç°":
            return self._generate_core_findings_section(analysis_data)
        elif section == "å…³é”®å»ºè®®":
            return await self._generate_key_recommendations_section(analysis_data, risk_assessment)
        elif section == "åç»­è¡ŒåŠ¨":
            return self._generate_next_steps_section(analysis_data, risk_assessment)
        elif section == "ç®€å•æ‘˜è¦":
            return self._generate_simple_summary_section(analysis_data, risk_assessment)
        elif section == "æ‚¨çš„å¥åº·çŠ¶å†µ":
            return self._generate_health_status_section(analysis_data, risk_assessment)
        elif section == "å¥åº·å»ºè®®":
            return await self._generate_health_advice_section(analysis_data, risk_assessment)
        elif section == "ä¸‹ä¸€æ­¥è¡ŒåŠ¨":
            return self._generate_next_actions_section(analysis_data, risk_assessment)
        elif section == "å¸¸è§é—®é¢˜":
            return self._generate_faq_section(analysis_data, risk_assessment)
        else:
            return f"## {section}\n\nè¯¥ç« èŠ‚å†…å®¹æ­£åœ¨ç”Ÿæˆä¸­...\n"
    
    async def _generate_executive_summary_section(self, analysis_data: Dict[str, Any],
                                                risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦ç« èŠ‚"""
        content = ""
        
        # æ•°æ®æ¦‚è§ˆ
        if analysis_data.get('responses_count'):
            content += f"æœ¬æ¬¡åˆ†æåŸºäº{analysis_data['responses_count']}ä¸ªé—®å·å›ç­”ã€‚"
        
        # é£é™©è¯„ä¼°æ‘˜è¦
        if risk_assessment:
            risk_level_emoji = {
                "low": "ğŸŸ¢",
                "medium": "ğŸŸ¡", 
                "high": "ğŸ”´"
            }
            emoji = risk_level_emoji.get(risk_assessment.overall_risk.value, "âšª")
            content += f"\n\n**é£é™©è¯„ä¼°**: {emoji} {risk_assessment.overall_risk.value.upper()}é£é™©"
            content += f"\n- é£é™©è¯„åˆ†: {risk_assessment.risk_score:.1f}"
            content += f"\n- ä¸»è¦é£é™©å› ç´ : {len(risk_assessment.risk_factors)}ä¸ª"
        
        # å…³é”®æ´å¯Ÿ
        insights = analysis_data.get('insights', [])
        if insights:
            content += f"\n\n**å…³é”®æ´å¯Ÿ**:"
            for i, insight in enumerate(insights[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                content += f"\n{i}. {insight.get('title', 'N/A')}"
        
        # æ•°æ®è´¨é‡
        quality = analysis_data.get('data_quality', {})
        if quality.get('overall_score'):
            content += f"\n\n**æ•°æ®è´¨é‡**: æ€»ä½“è¯„åˆ† {quality['overall_score']:.2f}/1.00"
        
        return content
    
    def _generate_background_section(self, questionnaire: Optional[Questionnaire],
                                   user_profile: Optional[Dict[str, Any]]) -> str:
        """ç”ŸæˆèƒŒæ™¯ä»‹ç»ç« èŠ‚"""
        content = "## èƒŒæ™¯ä»‹ç»\n\n"
        
        if questionnaire:
            content += f"**é—®å·ä¿¡æ¯**:\n"
            content += f"- æ ‡é¢˜: {questionnaire.title}\n"
            content += f"- æè¿°: {questionnaire.description}\n"
            content += f"- ç‰ˆæœ¬: {questionnaire.version}\n"
            content += f"- é—®é¢˜æ•°é‡: {len(questionnaire.questions)}ä¸ª\n"
            content += f"- é¢„è®¡å®Œæˆæ—¶é—´: {questionnaire.estimated_time}\n"
            content += f"- é—®é¢˜åˆ†ç±»: {', '.join(questionnaire.categories)}\n\n"
        
        if user_profile:
            content += f"**ç”¨æˆ·èƒŒæ™¯**:\n"
            for key, value in user_profile.items():
                if key not in ['session_id', 'password']:  # æ’é™¤æ•æ„Ÿä¿¡æ¯
                    content += f"- {key}: {value}\n"
            content += "\n"
        
        content += "æœ¬æŠ¥å‘Šæ—¨åœ¨é€šè¿‡ä¸“ä¸šçš„é—®å·åˆ†æï¼Œä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„å¥åº·é£é™©è¯„ä¼°å’Œæ”¹å–„å»ºè®®ã€‚"
        
        return content
    
    def _generate_data_overview_section(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®æ¦‚è§ˆç« èŠ‚"""
        content = "## æ•°æ®æ¦‚è§ˆ\n\n"
        
        # åŸºç¡€ç»Ÿè®¡
        basic_stats = analysis_data.get('basic_statistics', {})
        if basic_stats:
            content += f"**åŸºç¡€ç»Ÿè®¡ä¿¡æ¯**:\n"
            content += f"- æ€»å›ç­”æ•°: {basic_stats.get('total_responses', 0)}\n"
            content += f"- å”¯ä¸€é—®é¢˜æ•°: {basic_stats.get('unique_questions', 0)}\n"
            if basic_stats.get('completion_time'):
                content += f"- å®Œæˆæ—¶é—´: {basic_stats.get('completion_time'):.1f}ç§’\n"
            content += "\n"
        
        # åˆ†ç±»åˆ†æ
        category_analysis = analysis_data.get('category_analysis', {})
        if category_analysis:
            content += f"**åˆ†ç±»åˆ†æ**:\n"
            for category, stats in category_analysis.items():
                completion_rate = stats.get('completion_rate', 0) * 100
                content += f"- {category}: {stats.get('question_count', 0)}ä¸ªé—®é¢˜ï¼Œ"
                content += f"å®Œæˆç‡ {completion_rate:.1f}%\n"
            content += "\n"
        
        # æ•°æ®è´¨é‡
        quality = analysis_data.get('data_quality', {})
        if quality:
            content += f"**æ•°æ®è´¨é‡è¯„ä¼°**:\n"
            content += f"- å®Œæ•´æ€§: {quality.get('completeness', 0):.1%}\n"
            content += f"- ä¸€è‡´æ€§: {quality.get('consistency', 0):.1%}\n"
            content += f"- æœ‰æ•ˆæ€§: {quality.get('validity', 0):.1%}\n"
            content += f"- åŠæ—¶æ€§: {quality.get('timeliness', 0):.1%}\n"
            content += f"- æ€»ä½“è¯„åˆ†: {quality.get('overall_score', 0):.2f}/1.00\n"
        
        return content
    
    def _generate_risk_assessment_section(self, risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆé£é™©è¯„ä¼°ç« èŠ‚"""
        content = "## é£é™©è¯„ä¼°\n\n"
        
        if not risk_assessment:
            content += "é£é™©è¯„ä¼°æ•°æ®ä¸å¯ç”¨ã€‚\n"
            return content
        
        # æ€»ä½“é£é™©è¯„ä¼°
        risk_level_emoji = {
            "low": "ğŸŸ¢",
            "medium": "ğŸŸ¡",
            "high": "ğŸ”´"
        }
        emoji = risk_level_emoji.get(risk_assessment.overall_risk.value, "âšª")
        
        content += f"**æ€»ä½“é£é™©è¯„ä¼°**: {emoji} {risk_assessment.overall_risk.value.upper()}é£é™©\n\n"
        content += f"- **é£é™©è¯„åˆ†**: {risk_assessment.risk_score:.1f}\n"
        content += f"- **è¯„ä¼°æ—¶é—´**: {risk_assessment.assessed_at.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n\n"
        
        # é£é™©å› ç´ åˆ†æ
        if risk_assessment.risk_factors:
            content += f"**é£é™©å› ç´ åˆ†æ**:\n\n"
            for i, factor in enumerate(risk_assessment.risk_factors, 1):
                content += f"{i}. **{factor.get('name', 'N/A')}**\n"
                content += f"   - é£é™©ç­‰çº§: {factor.get('level', 'N/A')}\n"
                content += f"   - é£é™©è¯„åˆ†: {factor.get('score', 0):.1f}\n"
                content += f"   - è¯¦ç»†ä¿¡æ¯: {factor.get('details', 'N/A')}\n"
                content += f"   - è¯´æ˜: {factor.get('description', 'N/A')}\n\n"
        
        return content
    
    def _generate_data_analysis_section(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®åˆ†æç« èŠ‚"""
        content = "## æ•°æ®åˆ†æ\n\n"
        
        # æ¨¡å¼è¯†åˆ«
        pattern_analysis = analysis_data.get('pattern_analysis', {})
        if pattern_analysis:
            content += f"**æ¨¡å¼è¯†åˆ«ç»“æœ**:\n\n"
            
            identified_patterns = pattern_analysis.get('identified_patterns', [])
            if identified_patterns:
                content += f"**è¯†åˆ«çš„ä¸»è¦æ¨¡å¼**:\n"
                for i, pattern in enumerate(identified_patterns, 1):
                    content += f"{i}. {pattern}\n"
                content += "\n"
            
            anomaly_patterns = pattern_analysis.get('anomaly_patterns', [])
            if anomaly_patterns:
                content += f"**å¼‚å¸¸æ¨¡å¼**:\n"
                for i, pattern in enumerate(anomaly_patterns, 1):
                    content += f"{i}. {pattern}\n"
                content += "\n"
            
            behavioral_insights = pattern_analysis.get('behavioral_insights', [])
            if behavioral_insights:
                content += f"**è¡Œä¸ºæ´å¯Ÿ**:\n"
                for i, insight in enumerate(behavioral_insights, 1):
                    content += f"{i}. {insight}\n"
                content += "\n"
        
        # æ´å¯Ÿåˆ†æ
        insights = analysis_data.get('insights', [])
        if insights:
            content += f"**æ•°æ®æ´å¯Ÿ**:\n\n"
            for i, insight in enumerate(insights, 1):
                significance_emoji = {
                    "high": "ğŸ”´",
                    "medium": "ğŸŸ¡",
                    "low": "ğŸŸ¢"
                }
                emoji = significance_emoji.get(insight.get('significance', 'medium'), 'ğŸŸ¡')
                content += f"{i}. {emoji} **{insight.get('title', 'N/A')}**\n"
                content += f"   {insight.get('description', 'N/A')}\n"
                content += f"   é‡è¦æ€§: {insight.get('significance', 'N/A')}\n\n"
        
        return content
    
    def _generate_key_findings_section(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå…³é”®å‘ç°ç« èŠ‚"""
        content = "## å…³é”®å‘ç°\n\n"
        
        # æ•°æ®è´¨é‡å‘ç°
        quality = analysis_data.get('data_quality', {})
        if quality:
            content += f"**æ•°æ®è´¨é‡å‘ç°**:\n"
            if quality.get('overall_score', 0) >= 0.8:
                content += f"- ğŸŸ¢ æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œæ€»ä½“è¯„åˆ† {quality['overall_score']:.2f}/1.00\n"
            elif quality.get('overall_score', 0) >= 0.6:
                content += f"- ğŸŸ¡ æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ€»ä½“è¯„åˆ† {quality['overall_score']:.2f}/1.00\n"
            else:
                content += f"- ğŸ”´ æ•°æ®è´¨é‡éœ€è¦æ”¹å–„ï¼Œæ€»ä½“è¯„åˆ† {quality['overall_score']:.2f}/1.00\n"
            
            # å…·ä½“è´¨é‡é—®é¢˜
            quality_issues = quality.get('quality_issues', [])
            if quality_issues:
                content += f"- ä¸»è¦é—®é¢˜:\n"
                for issue in quality_issues:
                    content += f"  â€¢ {issue}\n"
            content += "\n"
        
        # æ¨¡å¼å‘ç°
        pattern_analysis = analysis_data.get('pattern_analysis', {})
        if pattern_analysis:
            identified_patterns = pattern_analysis.get('identified_patterns', [])
            if identified_patterns:
                content += f"**æ¨¡å¼å‘ç°**:\n"
                for i, pattern in enumerate(identified_patterns, 1):
                    content += f"{i}. {pattern}\n"
                content += "\n"
        
        # æ´å¯Ÿå‘ç°
        insights = analysis_data.get('insights', [])
        if insights:
            content += f"**æ´å¯Ÿå‘ç°**:\n"
            high_significance = [i for i in insights if i.get('significance') == 'high']
            if high_significance:
                content += f"- å‘ç° {len(high_significance)} ä¸ªé«˜é‡è¦æ€§æ´å¯Ÿ\n"
            content += f"- æ€»è®¡ {len(insights)} ä¸ªæ´å¯Ÿ\n\n"
        
        return content
    
    async def _generate_recommendations_section(self, analysis_data: Dict[str, Any],
                                              risk_assessment: Optional[RiskAssessment],
                                              user_profile: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆå»ºè®®å’Œè¡ŒåŠ¨æ–¹æ¡ˆç« èŠ‚"""
        content = "## å»ºè®®å’Œè¡ŒåŠ¨æ–¹æ¡ˆ\n\n"
        
        # é£é™©è¯„ä¼°å»ºè®®
        if risk_assessment:
            content += f"**åŸºäºé£é™©è¯„ä¼°çš„å»ºè®®**:\n\n"
            
            if risk_assessment.recommendations:
                for i, rec in enumerate(risk_assessment.recommendations, 1):
                    content += f"{i}. {rec}\n"
                content += "\n"
            
            # æ ¹æ®é£é™©ç­‰çº§ç»™å‡ºå…·ä½“å»ºè®®
            risk_level = risk_assessment.overall_risk.value
            if risk_level == "high":
                content += f"**é«˜é£é™©äººç¾¤ç‰¹åˆ«å»ºè®®**:\n"
                content += f"- ç«‹å³å°±åŒ»è¿›è¡Œè¯¦ç»†æ£€æŸ¥\n"
                content += f"- å®šæœŸè¿›è¡Œä¸“ä¸šåŒ»å­¦è¯„ä¼°\n"
                content += f"- å¯†åˆ‡å…³æ³¨ç—‡çŠ¶å˜åŒ–\n"
                content += f"- å¯»æ±‚ä¸“ä¸šå¥åº·ç®¡ç†æŒ‡å¯¼\n\n"
            elif risk_level == "medium":
                content += f"**ä¸­é£é™©äººç¾¤å»ºè®®**:\n"
                content += f"- å®šæœŸä½“æ£€å’Œç›‘æµ‹\n"
                content += f"- æ”¹å–„ç”Ÿæ´»æ–¹å¼\n"
                content += f"- å…³æ³¨æ—©æœŸç—‡çŠ¶\n"
                content += f"- å»ºç«‹å¥åº·æ¡£æ¡ˆ\n\n"
            else:
                content += f"**ä½é£é™©äººç¾¤å»ºè®®**:\n"
                content += f"- ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼\n"
                content += f"- å®šæœŸä½“æ£€\n"
                content += f"- é¢„é˜²æ€§å¥åº·ç®¡ç†\n\n"
        
        # æ•°æ®è´¨é‡å»ºè®®
        quality = analysis_data.get('data_quality', {})
        if quality:
            content += f"**æ•°æ®è´¨é‡æ”¹å–„å»ºè®®**:\n"
            if quality.get('completeness', 0) < 0.8:
                content += f"- æé«˜é—®å·å®Œæˆç‡\n"
            if quality.get('consistency', 0) < 0.7:
                content += f"- æ”¹å–„é—®é¢˜è®¾è®¡ï¼Œæé«˜ç­”æ¡ˆä¸€è‡´æ€§\n"
            if quality.get('validity', 0) < 0.9:
                content += f"- åŠ å¼ºç­”æ¡ˆéªŒè¯æœºåˆ¶\n"
            content += "\n"
        
        # ä¸ªæ€§åŒ–å»ºè®®
        if user_profile:
            content += f"**ä¸ªæ€§åŒ–å»ºè®®**:\n"
            age = user_profile.get('age')
            if age and int(age) > 50:
                content += f"- å»ºè®®å¢åŠ ä½“æ£€é¢‘ç‡\n"
                content += f"- å…³æ³¨å¹´é¾„ç›¸å…³å¥åº·é£é™©\n"
            content += "\n"
        
        return content
    
    def _generate_appendix_section(self, analysis_data: Dict[str, Any],
                                 questionnaire: Optional[Questionnaire]) -> str:
        """ç”Ÿæˆé™„å½•ç« èŠ‚"""
        content = "## é™„å½•\n\n"
        
        # æŠ€æœ¯ç»†èŠ‚
        content += f"**æŠ€æœ¯ä¿¡æ¯**:\n"
        content += f"- åˆ†ææ—¶é—´: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n"
        content += f"- åˆ†æå·¥å…·: MetaGPTæ™ºèƒ½ä½“ç³»ç»Ÿ\n"
        content += f"- æ•°æ®æ ¼å¼: JSON\n\n"
        
        # é—®å·è¯¦æƒ…
        if questionnaire:
            content += f"**é—®å·è¯¦æƒ…**:\n"
            content += f"- é—®å·ID: {questionnaire.id}\n"
            content += f"- åˆ›å»ºæ—¶é—´: {questionnaire.created_at.strftime('%Yå¹´%mæœˆ%dæ—¥')}\n"
            content += f"- é—®é¢˜åˆ†ç±»: {', '.join(questionnaire.categories)}\n\n"
        
        # æ•°æ®ç»Ÿè®¡
        if analysis_data:
            content += f"**æ•°æ®ç»Ÿè®¡**:\n"
            content += f"- å›ç­”æ•°é‡: {analysis_data.get('responses_count', 0)}\n"
            content += f"- åˆ†æç±»å‹: {analysis_data.get('analysis_type', 'N/A')}\n"
            content += f"- æ•°æ®è´¨é‡è¯„åˆ†: {analysis_data.get('data_quality', {}).get('overall_score', 0):.2f}\n"
        
        return content
    
    async def _generate_executive_summary(self, report_content: str) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        try:
            prompt = ReportGenerationPrompts.executive_summary_prompt(report_content)
            llm_response = await self.call_llm(prompt)
            return llm_response
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡Œæ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            return self._extract_executive_summary(report_content)
    
    def _extract_executive_summary(self, report_content: str) -> str:
        """æå–æ‰§è¡Œæ‘˜è¦"""
        # ç®€å•çš„æ‘˜è¦æå–é€»è¾‘
        lines = report_content.split('\n')
        summary_lines = []
        
        for line in lines:
            if line.startswith('## æ‰§è¡Œæ‘˜è¦') or line.startswith('## æ ¸å¿ƒå‘ç°'):
                continue
            elif line.startswith('##'):
                break
            elif line.strip():
                summary_lines.append(line.strip())
        
        return '\n'.join(summary_lines[:10])  # é™åˆ¶å‰10è¡Œ
    
    def _create_default_risk_assessment(self) -> RiskAssessment:
        """åˆ›å»ºé»˜è®¤é£é™©è¯„ä¼°"""
        from ..models.questionnaire import RiskLevel
        
        return RiskAssessment(
            session_id="unknown",
            overall_risk=RiskLevel.MEDIUM,
            risk_score=3.0,
            risk_factors=[{
                "factor": "default",
                "name": "é»˜è®¤è¯„ä¼°",
                "level": "moderate",
                "score": 3.0,
                "details": "é£é™©è¯„ä¼°æ•°æ®ä¸å¯ç”¨",
                "description": "å»ºè®®è¿›è¡Œä¸“ä¸šåŒ»å­¦è¯„ä¼°"
            }],
            recommendations=[
                "å»ºè®®è¿›è¡Œä¸“ä¸šåŒ»å­¦è¯„ä¼°",
                "å®šæœŸè¿›è¡Œå¥åº·æ£€æŸ¥",
                "ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼"
            ]
        )
    
    def _create_error_report(self, error_message: str, user_profile: Optional[Dict[str, Any]]) -> AnalysisReport:
        """åˆ›å»ºé”™è¯¯æŠ¥å‘Š"""
        return AnalysisReport(
            session_id=user_profile.get('session_id', 'unknown') if user_profile else 'unknown',
            title="æŠ¥å‘Šç”Ÿæˆå¤±è´¥",
            content=f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {error_message}",
            risk_assessment=self._create_default_risk_assessment(),
            data_insights=[],
            generated_at=datetime.now()
        )
    
    # å…¶ä»–ç« èŠ‚ç”Ÿæˆæ–¹æ³•çš„ç®€åŒ–å®ç°
    def _generate_core_findings_section(self, analysis_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ ¸å¿ƒå‘ç°ç« èŠ‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        return self._generate_key_findings_section(analysis_data)
    
    async def _generate_key_recommendations_section(self, analysis_data: Dict[str, Any],
                                                  risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆå…³é”®å»ºè®®ç« èŠ‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        return await self._generate_recommendations_section(analysis_data, risk_assessment, {})
    
    def _generate_next_steps_section(self, analysis_data: Dict[str, Any],
                                   risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆåç»­è¡ŒåŠ¨ç« èŠ‚"""
        content = "## åç»­è¡ŒåŠ¨\n\n"
        content += "1. å®šæœŸå¤æŸ¥å’Œç›‘æµ‹\n"
        content += "2. æ‰§è¡Œå¥åº·æ”¹å–„è®¡åˆ’\n"
        content += "3. å¯»æ±‚ä¸“ä¸šåŒ»ç–—å»ºè®®\n"
        content += "4. å»ºç«‹å¥åº·æ¡£æ¡ˆ\n"
        return content
    
    def _generate_simple_summary_section(self, analysis_data: Dict[str, Any],
                                       risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆç®€å•æ‘˜è¦ç« èŠ‚"""
        return self._generate_executive_summary_section(analysis_data, risk_assessment)
    
    def _generate_health_status_section(self, analysis_data: Dict[str, Any],
                                      risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆå¥åº·çŠ¶å†µç« èŠ‚"""
        content = "## æ‚¨çš„å¥åº·çŠ¶å†µ\n\n"
        if risk_assessment:
            content += f"æ ¹æ®é—®å·åˆ†æï¼Œæ‚¨çš„å¥åº·é£é™©ç­‰çº§ä¸º: {risk_assessment.overall_risk.value.upper()}\n"
            content += f"é£é™©è¯„åˆ†: {risk_assessment.risk_score:.1f}\n"
        return content
    
    async def _generate_health_advice_section(self, analysis_data: Dict[str, Any],
                                            risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆå¥åº·å»ºè®®ç« èŠ‚"""
        return await self._generate_recommendations_section(analysis_data, risk_assessment, {})
    
    def _generate_next_actions_section(self, analysis_data: Dict[str, Any],
                                     risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨ç« èŠ‚"""
        return self._generate_next_steps_section(analysis_data, risk_assessment)
    
    def _generate_faq_section(self, analysis_data: Dict[str, Any],
                            risk_assessment: Optional[RiskAssessment]) -> str:
        """ç”Ÿæˆå¸¸è§é—®é¢˜ç« èŠ‚"""
        content = "## å¸¸è§é—®é¢˜\n\n"
        content += "**Q: è¿™ä¸ªæŠ¥å‘Šå‡†ç¡®å—ï¼Ÿ**\n"
        content += "A: æœ¬æŠ¥å‘ŠåŸºäºæ‚¨æä¾›çš„é—®å·å›ç­”ç”Ÿæˆï¼Œå»ºè®®ç»“åˆä¸“ä¸šåŒ»ç–—å»ºè®®ä½¿ç”¨ã€‚\n\n"
        content += "**Q: æˆ‘éœ€è¦ç«‹å³å°±åŒ»å—ï¼Ÿ**\n"
        content += "A: è¯·æ ¹æ®é£é™©è¯„ä¼°ç»“æœå’Œæ‚¨çš„å…·ä½“æƒ…å†µå†³å®šï¼Œå¦‚æœ‰ç–‘é—®è¯·å’¨è¯¢åŒ»ç”Ÿã€‚\n\n"
        content += "**Q: å¦‚ä½•æ”¹å–„æˆ‘çš„å¥åº·çŠ¶å†µï¼Ÿ**\n"
        content += "A: è¯·å‚è€ƒæŠ¥å‘Šä¸­çš„å…·ä½“å»ºè®®ï¼Œå¹¶å’¨è¯¢ä¸“ä¸šå¥åº·ç®¡ç†å¸ˆã€‚\n"
        return content
    
    def get_report_templates(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æŠ¥å‘Šæ¨¡æ¿"""
        return self.report_templates
    
    def get_generated_reports(self) -> List[AnalysisReport]:
        """è·å–å·²ç”Ÿæˆçš„æŠ¥å‘Š"""
        return self.generated_reports
    
    def export_report(self, report: AnalysisReport, format: str = "markdown",
                     output_path: Optional[str] = None) -> str:
        """å¯¼å‡ºæŠ¥å‘Š"""
        if format.lower() == "markdown":
            content = report.content
        elif format.lower() == "json":
            content = json.dumps(report.to_dict(), ensure_ascii=False, indent=2)
        elif format.lower() == "text":
            content = self._convert_markdown_to_text(report.content)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format}")
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if output_path:
            output_file = Path(output_path)
            output_file.parent.mkdir(parents=True, exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(content)
            logger.info(f"âœ… æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
        
        return content
    
    def _convert_markdown_to_text(self, markdown_content: str) -> str:
        """å°†Markdownè½¬æ¢ä¸ºçº¯æ–‡æœ¬"""
        # ç®€å•çš„Markdownåˆ°æ–‡æœ¬è½¬æ¢
        text = markdown_content
        
        # ç§»é™¤æ ‡é¢˜æ ‡è®°
        text = text.replace('#', '')
        text = text.replace('**', '')
        text = text.replace('*', '')
        
        # ç§»é™¤å¤šä½™ç©ºè¡Œ
        lines = text.split('\n')
        cleaned_lines = []
        for line in lines:
            if line.strip():
                cleaned_lines.append(line.strip())
        
        return '\n'.join(cleaned_lines)

if __name__ == "__main__":
    # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“
    print("=== æŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“æµ‹è¯• ===")
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    generator = ReportGeneratorAgent()
    print(f"æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ: {generator}")
    
    # æµ‹è¯•æ¨¡æ¿è·å–
    templates = generator.get_report_templates()
    print(f"å¯ç”¨æ¨¡æ¿: {list(templates.keys())}")
    
    # æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ
    import asyncio
    
    async def test_report_generation():
        # æ¨¡æ‹Ÿåˆ†ææ•°æ®
        analysis_data = {
            "responses_count": 15,
            "insights": [
                {"title": "æ•°æ®è´¨é‡è‰¯å¥½", "description": "é—®å·å®Œæˆåº¦é«˜", "significance": "high"}
            ],
            "data_quality": {"overall_score": 0.85}
        }
        
        report = await generator.generate_report(
            analysis_data=analysis_data,
            report_type="executive"
        )
        
        print(f"æŠ¥å‘Šç”ŸæˆæˆåŠŸ: {report.title}")
        print(f"æŠ¥å‘Šé•¿åº¦: {len(report.content)} å­—ç¬¦")
        
        # å¯¼å‡ºæŠ¥å‘Š
        markdown_content = generator.export_report(report, "markdown")
        print(f"MarkdownæŠ¥å‘Šé¢„è§ˆ:\n{markdown_content[:200]}...")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_report_generation())
    
    print("âœ… æŠ¥å‘Šç”Ÿæˆæ™ºèƒ½ä½“æµ‹è¯•å®Œæˆ")
