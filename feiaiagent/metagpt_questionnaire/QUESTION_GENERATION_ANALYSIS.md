# ğŸ“‹ MetaGPTé—®å·ç³»ç»Ÿé—®é¢˜ç”Ÿæˆæœºåˆ¶åˆ†æ

## ğŸ¯ æ¦‚è¿°

MetaGPTé—®å·ç³»ç»Ÿé‡‡ç”¨äº†**å¤šå±‚æ¬¡ã€æ™ºèƒ½åŒ–**çš„é—®é¢˜ç”Ÿæˆæœºåˆ¶ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸åŒçš„éœ€æ±‚å’Œåœºæ™¯åŠ¨æ€ç”Ÿæˆé—®é¢˜ã€‚ç³»ç»Ÿæ”¯æŒä¸‰ç§ä¸»è¦æ¨¡å¼ï¼š**æœ¬åœ°é—®å·æ¨¡å¼**ã€**LLMç”Ÿæˆæ¨¡å¼**å’Œ**æ™ºèƒ½é€‰æ‹©æ¨¡å¼**ã€‚

## ğŸ—ï¸ é—®é¢˜ç”Ÿæˆæ¶æ„

```mermaid
graph TB
    A[é—®å·éœ€æ±‚è¾“å…¥] --> B{é—®é¢˜ç”Ÿæˆæ¨¡å¼é€‰æ‹©}
    
    B -->|æœ¬åœ°æ¨¡å¼| C[QuestionnaireDesignerAgent]
    B -->|LLMæ¨¡å¼| D[LLMç”Ÿæˆ]
    B -->|æ™ºèƒ½æ¨¡å¼| E[IntelligentQuestionSelectorAgent]
    
    C --> F[local_questionnaire_enhanced.py]
    F --> G[QUESTIONS_STRUCTURED_ENHANCED]
    
    D --> H[è®¾è®¡æç¤ºè¯]
    H --> I[LLMå“åº”è§£æ]
    I --> J[ç»“æ„åŒ–é—®é¢˜]
    
    E --> K[é—®é¢˜ä¼˜å…ˆçº§è®¡ç®—]
    K --> L[æ™ºèƒ½é—®é¢˜é€‰æ‹©]
    
    G --> M[é—®é¢˜å¯¹è±¡åˆ›å»º]
    J --> M
    L --> M
    
    M --> N[Questionnaireå¯¹è±¡]
    N --> O[é—®é¢˜æµç¨‹æ§åˆ¶]
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶åˆ†æ

### 1. **é—®å·è®¾è®¡å™¨** (`QuestionnaireDesignerAgent`)

#### ä¸»è¦åŠŸèƒ½
- è´Ÿè´£é—®å·çš„æ•´ä½“è®¾è®¡å’Œé—®é¢˜ç”Ÿæˆ
- æ”¯æŒå¤šç§æ•°æ®æºï¼šæœ¬åœ°é—®å·ã€LLMç”Ÿæˆã€æ¨¡æ¿ç”Ÿæˆ
- å¤„ç†é—®é¢˜ä¾èµ–å…³ç³»å’ŒéªŒè¯è§„åˆ™

#### é—®é¢˜ç”Ÿæˆæµç¨‹
```python
async def design_questionnaire(self, requirements: Dict[str, Any]) -> Questionnaire:
    """è®¾è®¡é—®å·çš„ä¸»è¦æµç¨‹"""
    
    # 1. æ£€æŸ¥æ•°æ®æºç±»å‹
    source = requirements.get('source') or requirements.get('template_type')
    
    if source == 'local':
        # æœ¬åœ°é—®å·æ¨¡å¼ - ä»local_questionnaire_enhanced.pyåŠ è½½
        questionnaire = self._create_from_local_questionnaire(local_path)
    else:
        # LLMç”Ÿæˆæ¨¡å¼
        prompt = self.get_prompt("questionnaire_design", ...)
        llm_response = await self.call_llm(prompt)
        questionnaire_data = self._parse_llm_response(llm_response)
        questionnaire = self._create_questionnaire_from_data(questionnaire_data)
    
    # 2. éªŒè¯é—®å·å®Œæ•´æ€§
    self._validate_questionnaire(questionnaire)
    
    return questionnaire
```

#### æœ¬åœ°é—®å·åŠ è½½æœºåˆ¶
```python
def _create_from_local_questionnaire(self, local_path: Optional[str] = None) -> Questionnaire:
    """ä»æœ¬åœ°é—®å·å®šä¹‰æ„å»ºé—®å·"""
    
    # 1. å¯¼å…¥æœ¬åœ°æ¨¡å—
    module = self._import_local_questionnaire(local_path)
    
    # 2. ä¼˜å…ˆè¯»å–å¢å¼ºç‰ˆé—®å·å®šä¹‰
    questions_structured = (
        getattr(module, 'QUESTIONS_STRUCTURED_ENHANCED', None) or 
        getattr(module, 'questions_structured', None) or 
        getattr(module, 'QUESTIONS_STRUCTURED', None)
    )
    
    # 3. å¤„ç†ä¾èµ–å…³ç³»
    for question_data in questions_structured:
        if 'depends_on' in question_data:
            # å°†ä¾èµ–ä¿¡æ¯æ³¨å…¥åˆ°éªŒè¯è§„åˆ™ä¸­
            question.validation_rules = {
                'depends_on': question_data['depends_on']
            }
    
    return questionnaire
```

### 2. **æ™ºèƒ½é—®é¢˜é€‰æ‹©å™¨** (`IntelligentQuestionSelectorAgent`)

#### æ ¸å¿ƒåŠŸèƒ½
- åŸºäºç”¨æˆ·å›ç­”å’Œå¯¹è¯ä¸Šä¸‹æ–‡æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªé—®é¢˜
- å®ç°é—®é¢˜ä¼˜å…ˆçº§è¯„åˆ†ç³»ç»Ÿ
- æ”¯æŒæ¡ä»¶è·³é¢˜å’ŒåŠ¨æ€é—®é¢˜æµç¨‹

#### é—®é¢˜é€‰æ‹©ç®—æ³•
```python
async def select_next_question(self, answered_questions, available_questions, ...):
    """æ™ºèƒ½é€‰æ‹©ä¸‹ä¸€ä¸ªé—®é¢˜"""
    
    # 1. åˆ†æå¯¹è¯ä¸Šä¸‹æ–‡
    context_analysis = self._analyze_conversation_context(
        answered_questions, conversation_history, user_profile
    )
    
    # 2. è®¡ç®—æ¯ä¸ªé—®é¢˜çš„ä¼˜å…ˆçº§åˆ†æ•°
    question_scores = []
    for question in available_questions:
        score = await self._calculate_question_priority_score(
            question, context_analysis, answered_questions
        )
        question_scores.append((question, score))
    
    # 3. æŒ‰åˆ†æ•°æ’åºï¼Œé€‰æ‹©æœ€é«˜åˆ†çš„é—®é¢˜
    question_scores.sort(key=lambda x: x[1], reverse=True)
    
    return question_scores[0][0]  # è¿”å›æœ€é«˜åˆ†çš„é—®é¢˜
```

#### ä¼˜å…ˆçº§è¯„åˆ†ç³»ç»Ÿ
```python
def _calculate_question_priority_score(self, question, context, answered_questions) -> float:
    """è®¡ç®—é—®é¢˜ä¼˜å…ˆçº§åˆ†æ•°"""
    
    # 1. è·å–åŸºç¡€ä¼˜å…ˆçº§
    category = question.category
    base_config = self.question_priorities.get(category, {"base_priority": 50, "urgency_multiplier": 1.0})
    base_score = base_config["base_priority"]
    urgency_multiplier = base_config["urgency_multiplier"]
    
    adjustment_factors = 1.0
    
    # 2. æ£€æŸ¥ä¾èµ–æ¡ä»¶
    if question.validation_rules and 'depends_on' in question.validation_rules:
        dependency = question.validation_rules['depends_on']
        if not self._is_dependency_met(dependency, answered_questions):
            return 0  # ä¾èµ–ä¸æ»¡è¶³ï¼Œä¼˜å…ˆçº§ä¸º0
        adjustment_factors *= 1.2  # ä¾èµ–æ»¡è¶³çš„é—®é¢˜ç•¥å¾®æå‡ä¼˜å…ˆçº§
    
    # 3. æ£€æŸ¥æ˜¯å¦æ˜¯é«˜é£é™©å›ç­”çš„è·Ÿè¿›é—®é¢˜
    if self._is_follow_up_question(question, context):
        adjustment_factors *= 1.5
    
    # 4. æ£€æŸ¥æ˜¯å¦ä¸å·²è¯†åˆ«çš„é£é™©æŒ‡æ ‡å¼ºç›¸å…³
    if self._is_related_to_risk_indicators(question, context):
        adjustment_factors *= urgency_multiplier
    
    # 5. è€ƒè™‘ç”¨æˆ·æ¡£æ¡ˆ
    if user_profile := context.get("user_profile"):
        if user_profile.get("gender") == "2" and question.category == "å¨æˆ¿æ²¹çƒŸ":
            adjustment_factors *= 1.3  # å¥³æ€§ç”¨æˆ·å¯¹å¨æˆ¿æ²¹çƒŸé—®é¢˜ä¼˜å…ˆçº§æ›´é«˜
    
    # 6. è€ƒè™‘é—®é¢˜çš„é‡è¦æ€§
    if question.required:
        adjustment_factors *= 1.1
    
    return base_score * adjustment_factors
```

### 3. **å¯¹è¯å¼é¢è¯•å®˜** (`ConversationalInterviewerAgent`)

#### ä¸»è¦åŠŸèƒ½
- æä¾›å¯¹è¯å¼çš„é—®é¢˜ç”Ÿæˆå’Œä¼˜åŒ–
- åŸºäºå¯¹è¯å†å²æ¨æ–­ç”¨æˆ·ç‰¹å¾
- å®ç°æ™ºèƒ½è·³é¢˜é€»è¾‘

#### é—®é¢˜ç”Ÿæˆæµç¨‹
```python
async def process(self, session_data: Dict[str, Any]) -> Dict[str, Any]:
    """åŠ¨æ€ç¡®å®šå¹¶è¯¢é—®ä¸‹ä¸€ä¸ªæœ€ä½³é—®é¢˜"""
    
    # 1. æ„å»ºç­”æ¡ˆæ˜ å°„å’Œæ¨æ–­äº‹å®
    answers_by_id = {r.question_id: str(r.answer).strip() for r in responses}
    inferred_facts = self._infer_facts_from_history(responses, questionnaire)
    answers_merged = {**answers_by_id, **inferred_facts}
    
    # 2. ç¡®å®šè¦è·³è¿‡çš„é—®é¢˜
    skip_ids = self._get_skip_ids(answers_merged)
    
    # 3. è¿‡æ»¤å€™é€‰é—®é¢˜
    candidate_questions = []
    for q in questionnaire.questions:
        if q.id not in answers_merged and q.id not in skip_ids:
            if self._are_dependencies_met(q, answers_merged):
                candidate_questions.append(q)
    
    # 4. é€‰æ‹©ä¸‹ä¸€ä¸ªé—®é¢˜
    if len(candidate_questions) == 1:
        next_question = candidate_questions[0]
    else:
        next_question = await self._determine_next_question(
            responses, inferred_facts, candidate_questions, questionnaire
        )
    
    # 5. é‡æ–°è¡¨è¿°é—®é¢˜ä¸ºå¯¹è¯å¼è¯­è°ƒ
    rephrased_question = await self._rephrase_question(next_question, responses)
    
    return {
        "status": "in_progress",
        "question_text": rephrased_question,
        "question_id": next_question.id,
        "next_index": questionnaire.questions.index(next_question)
    }
```

## ğŸ“Š é—®é¢˜ç”Ÿæˆæ¨¡å¼å¯¹æ¯”

| æ¨¡å¼ | æ•°æ®æº | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|------|--------|------|----------|
| **æœ¬åœ°æ¨¡å¼** | `local_questionnaire_enhanced.py` | é¢„å®šä¹‰é—®é¢˜ï¼Œæ”¯æŒä¾èµ–å…³ç³» | æ ‡å‡†åŒ–é—®å·ï¼Œå¿«é€Ÿéƒ¨ç½² |
| **LLMæ¨¡å¼** | å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆ | åŠ¨æ€ç”Ÿæˆï¼Œä¸ªæ€§åŒ–å¼º | å®šåˆ¶åŒ–é—®å·ï¼Œåˆ›æ–°éœ€æ±‚ |
| **æ™ºèƒ½æ¨¡å¼** | ä¼˜å…ˆçº§ç®—æ³•é€‰æ‹© | æ™ºèƒ½æ’åºï¼Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ | å¤æ‚é—®å·ï¼Œä¸ªæ€§åŒ–ä½“éªŒ |

## ğŸ” é—®é¢˜ç”Ÿæˆè¯¦ç»†æµç¨‹

### é˜¶æ®µ1ï¼šé—®é¢˜å®šä¹‰å’ŒåŠ è½½

```python
# 1. é—®é¢˜å®šä¹‰ï¼ˆlocal_questionnaire_enhanced.pyï¼‰
QUESTIONS_STRUCTURED_ENHANCED = [
    {
        "id": "smoking_history",
        "text": "å¸çƒŸå²(1æ˜¯ 2å¦)",
        "prompt": "è¯·é—®æ‚¨æœ‰å¸çƒŸçš„ä¹ æƒ¯å—ï¼Ÿ",
        "category": "å¸çƒŸå²",
        "required": True
    },
    {
        "id": "smoking_freq",
        "text": "å¸çƒŸé¢‘ç‡(æ”¯/å¤©)",
        "prompt": "æ‚¨å¹³å‡æ¯å¤©å¤§æ¦‚æŠ½å¤šå°‘æ”¯çƒŸï¼Ÿ",
        "category": "å¸çƒŸå²",
        "depends_on": {"id": "smoking_history", "value": "1"},
        "required": True
    }
]

# 2. é—®å·è®¾è®¡å™¨åŠ è½½
questionnaire = await designer.design_questionnaire({
    "source": "local",
    "local_questionnaire_path": "path/to/local_questionnaire_enhanced.py"
})
```

### é˜¶æ®µ2ï¼šé—®é¢˜é€‰æ‹©å’Œæ’åº

```python
# 3. æ™ºèƒ½é—®é¢˜é€‰æ‹©å™¨å·¥ä½œ
selection_result = await question_selector.process({
    "answered_questions": answered_questions,
    "available_questions": available_questions,
    "conversation_history": conversation_history,
    "user_profile": user_profile
})

# 4. é—®é¢˜ä¼˜å…ˆçº§è®¡ç®—
for question in available_questions:
    score = calculate_priority_score(question, context)
    # åŸºäºåˆ†æ•°æ’åºé€‰æ‹©æœ€ä½³é—®é¢˜
```

### é˜¶æ®µ3ï¼šé—®é¢˜ä¼˜åŒ–å’Œè¡¨è¿°

```python
# 5. å¯¹è¯å¼ä¼˜åŒ–
rephrased_question = await interviewer._rephrase_question(selected_question, history)

# 6. è¿”å›æœ€ç»ˆé—®é¢˜
return {
    "question_text": rephrased_question,
    "question_id": selected_question.id,
    "category": selected_question.category,
    "selection_reason": "åŸºäºé£é™©è¯„ä¼°å’ŒåŒ»å­¦é€»è¾‘"
}
```

## ğŸ¯ å…³é”®ç‰¹æ€§

### 1. **æ¡ä»¶ä¾èµ–ç³»ç»Ÿ**
```python
# é—®é¢˜ä¾èµ–å…³ç³»å®šä¹‰
{
    "id": "smoking_freq",
    "depends_on": {"id": "smoking_history", "value": "1"}
}
# åªæœ‰åœ¨ç”¨æˆ·å›ç­”"æœ‰å¸çƒŸå²"æ—¶æ‰è¯¢é—®å¸çƒŸé¢‘ç‡
```

### 2. **æ™ºèƒ½è·³é¢˜é€»è¾‘**
```python
# åŸºäºç­”æ¡ˆè‡ªåŠ¨è·³è¿‡ä¸ç›¸å…³é—®é¢˜
if answers.get('smoking') == '2':  # ä¸å¸çƒŸ
    skip_ids.update(['smoking_years', 'daily_cigarettes', 'quit_years'])
```

### 3. **ä¼˜å…ˆçº§è¯„åˆ†ç³»ç»Ÿ**
```python
# ä¸åŒç±»åˆ«é—®é¢˜çš„ä¼˜å…ˆçº§é…ç½®
"å¸çƒŸå²": {"base_priority": 85, "urgency_multiplier": 1.5},
"è¿‘æœŸç—‡çŠ¶": {"base_priority": 95, "urgency_multiplier": 2.0},
"åŸºæœ¬ä¿¡æ¯": {"base_priority": 100, "urgency_multiplier": 1.0}
```

### 4. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥é€‰æ‹©**
```python
# åŸºäºç”¨æˆ·ç‰¹å¾è°ƒæ•´é—®é¢˜ä¼˜å…ˆçº§
if user_profile.get("gender") == "2" and question.category == "å¨æˆ¿æ²¹çƒŸ":
    adjustment_factors *= 1.3  # å¥³æ€§ç”¨æˆ·å¯¹å¨æˆ¿æ²¹çƒŸé—®é¢˜ä¼˜å…ˆçº§æ›´é«˜
```

## ğŸš€ å®é™…åº”ç”¨ç¤ºä¾‹

### åœºæ™¯1ï¼šé«˜é£é™©ç”¨æˆ·é—®å·
```python
# ç”¨æˆ·å›ç­”ï¼šæœ‰å¸çƒŸå² â†’ ç³»ç»Ÿè‡ªåŠ¨è¯¢é—®å¸çƒŸè¯¦æƒ…
# ç”¨æˆ·å›ç­”ï¼šæœ‰å®¶æ—å² â†’ ç³»ç»Ÿä¼˜å…ˆè¯¢é—®ç›¸å…³ç—‡çŠ¶
# ç”¨æˆ·å›ç­”ï¼šæœ‰ç—‡çŠ¶ â†’ ç³»ç»Ÿç«‹å³è¯¢é—®ç—‡çŠ¶è¯¦æƒ…
```

### åœºæ™¯2ï¼šä½é£é™©ç”¨æˆ·é—®å·
```python
# ç”¨æˆ·å›ç­”ï¼šä¸å¸çƒŸ â†’ ç³»ç»Ÿè·³è¿‡æ‰€æœ‰å¸çƒŸç›¸å…³é—®é¢˜
# ç”¨æˆ·å›ç­”ï¼šæ— å®¶æ—å² â†’ ç³»ç»Ÿè·³è¿‡å®¶æ—å²ç›¸å…³é—®é¢˜
# ç³»ç»Ÿè‡ªåŠ¨è°ƒæ•´é—®é¢˜é¡ºåºï¼Œä¼˜å…ˆè¯¢é—®åŸºæœ¬ä¿¡æ¯
```

## ğŸ“ˆ ç³»ç»Ÿä¼˜åŠ¿

1. **æ™ºèƒ½åŒ–ç¨‹åº¦é«˜** - åŸºäºAIç®—æ³•çš„é—®é¢˜é€‰æ‹©
2. **ä¸ªæ€§åŒ–ä½“éªŒ** - æ ¹æ®ç”¨æˆ·ç‰¹å¾è°ƒæ•´é—®é¢˜æµç¨‹
3. **åŒ»å­¦é€»è¾‘ä¸¥è°¨** - åŸºäºä¸´åºŠé—®è¯Šç»éªŒè®¾è®¡
4. **çµæ´»å¯æ‰©å±•** - æ”¯æŒå¤šç§é—®é¢˜ç”Ÿæˆæ¨¡å¼
5. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–** - å‡å°‘ä¸ç›¸å…³é—®é¢˜ï¼Œæé«˜æ•ˆç‡

## ğŸ”§ æŠ€æœ¯å®ç°è¦ç‚¹

### 1. **å¼‚æ­¥å¤„ç†**
```python
# æ‰€æœ‰é—®é¢˜ç”Ÿæˆæ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„
async def select_next_question(self, ...):
    # å¼‚æ­¥LLMè°ƒç”¨
    llm_response = await self.call_llm(prompt)
```

### 2. **é”™è¯¯å¤„ç†å’Œé™çº§**
```python
# å¤šå±‚é™çº§æœºåˆ¶
try:
    # å°è¯•æ™ºèƒ½é€‰æ‹©
    next_question = await self._determine_next_question(...)
except Exception:
    # é™çº§åˆ°ç®€å•é€‰æ‹©
    next_question = candidate_questions[0]
```

### 3. **æ€§èƒ½ä¼˜åŒ–**
```python
# é—®é¢˜ä¼˜å…ˆçº§ç¼“å­˜
self.question_priorities = self._initialize_question_priorities()

# ä¸Šä¸‹æ–‡åˆ†æç¼“å­˜
self.conversation_context = {}
```

## ğŸ‰ æ€»ç»“

MetaGPTé—®å·ç³»ç»Ÿçš„é—®é¢˜ç”Ÿæˆæœºåˆ¶æ˜¯ä¸€ä¸ª**å¤šå±‚æ¬¡ã€æ™ºèƒ½åŒ–ã€é«˜åº¦å¯å®šåˆ¶**çš„ç³»ç»Ÿï¼Œèƒ½å¤Ÿï¼š

- **ä»é¢„å®šä¹‰é—®é¢˜åº“ä¸­æ™ºèƒ½é€‰æ‹©**æœ€ç›¸å…³çš„é—®é¢˜
- **åŸºäºç”¨æˆ·å›ç­”åŠ¨æ€è°ƒæ•´**é—®é¢˜æµç¨‹
- **å®ç°æ¡ä»¶è·³é¢˜**ï¼Œé¿å…ä¸ç›¸å…³çš„é—®é¢˜
- **æä¾›ä¸ªæ€§åŒ–ä½“éªŒ**ï¼Œæ ¹æ®ç”¨æˆ·ç‰¹å¾ä¼˜åŒ–é—®é¢˜é¡ºåº
- **æ”¯æŒå¤šç§æ¨¡å¼**ï¼Œæ»¡è¶³ä¸åŒåœºæ™¯çš„éœ€æ±‚

è¿™ç§è®¾è®¡ä½¿å¾—é—®å·ç³»ç»Ÿæ—¢ä¿æŒäº†åŒ»å­¦é€»è¾‘çš„ä¸¥è°¨æ€§ï¼Œåˆæä¾›äº†è‰¯å¥½çš„ç”¨æˆ·ä½“éªŒï¼Œæ˜¯ä¸€ä¸ªçœŸæ­£æ™ºèƒ½åŒ–çš„é—®å·è§£å†³æ–¹æ¡ˆã€‚ğŸš€
